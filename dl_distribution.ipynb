{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(input_dim, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        weights = self.attention(x)\n",
    "        return weights * x\n",
    "\n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_size, num_classes):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.spatial_attention = SpatialAttention(input_dim + num_classes)\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim + num_classes, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.BatchNorm1d(hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.fc_mu = nn.Linear(hidden_size // 2, latent_dim)\n",
    "        self.fc_var = nn.Linear(hidden_size // 2, latent_dim)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim + num_classes, hidden_size // 2),\n",
    "            nn.BatchNorm1d(hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size // 2, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def encode(self, x, c):\n",
    "        c_onehot = torch.zeros(c.size(0), self.num_classes).to(x.device)\n",
    "        c_onehot.scatter_(1, c.unsqueeze(1), 1)\n",
    "        x_c = torch.cat([x, c_onehot], dim=1)\n",
    "        x_c = self.spatial_attention(x_c)\n",
    "        h = self.encoder(x_c)\n",
    "        return self.fc_mu(h), self.fc_var(h)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z, c):\n",
    "        c_onehot = torch.zeros(c.size(0), self.num_classes).to(z.device)\n",
    "        c_onehot.scatter_(1, c.unsqueeze(1), 1)\n",
    "        z_c = torch.cat([z, c_onehot], dim=1)\n",
    "        return self.decoder(z_c)\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        mu, logvar = self.encode(x, c)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z, c), mu, logvar\n",
    "\n",
    "class SpatialAssignment:\n",
    "    def __init__(self, adata, target_positions, latent_dim=32, hidden_size=256, lr=1e-4, batch_size=64, num_epochs=200):\n",
    "        self.adata = adata\n",
    "        self.target_positions = target_positions\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        self.ground_truth = adata.obs['Ground Truth'].values if 'Ground Truth' in adata.obs.columns else adata.obs['layer_guess'].values\n",
    "        self.le = LabelEncoder()\n",
    "        self.ground_truth_encoded = self.le.fit_transform(self.ground_truth)  # Encode string labels\n",
    "        self.num_classes = len(self.le.classes_)\n",
    "        \n",
    "        self.scaler = StandardScaler()\n",
    "        self.spatial_coords = adata.obsm['spatial']\n",
    "        self.spatial_coords_normalized = self.scaler.fit_transform(self.spatial_coords)\n",
    "        self.target_positions_normalized = self.scaler.transform(target_positions)\n",
    "        \n",
    "        self.cvae = CVAE(\n",
    "            input_dim=self.spatial_coords_normalized.shape[1],\n",
    "            latent_dim=latent_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_classes=self.num_classes\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.cvae.parameters(), lr=lr)\n",
    "        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=num_epochs)\n",
    "\n",
    "    def assign_cell_types(self):\n",
    "        self.cvae.eval()\n",
    "        with torch.no_grad():\n",
    "            # Calculate original proportions using encoded labels\n",
    "            original_counts = pd.Series(self.ground_truth_encoded).value_counts()\n",
    "            total_original = len(self.ground_truth_encoded)\n",
    "            original_proportions = original_counts / total_original\n",
    "            \n",
    "            # Calculate target counts using encoded labels\n",
    "            target_total = len(self.target_positions)\n",
    "            target_counts = (original_proportions * target_total).round().astype(int)\n",
    "            target_counts.index = target_counts.index.astype(int)  # Ensure index is integer type\n",
    "            \n",
    "            # Adjust target counts to match total\n",
    "            while target_counts.sum() != target_total:\n",
    "                if target_counts.sum() < target_total:\n",
    "                    target_counts[target_counts.idxmin()] += 1\n",
    "                else:\n",
    "                    target_counts[target_counts.idxmax()] -= 1\n",
    "            \n",
    "            # Generate initial labels using CVAE\n",
    "            initial_labels = self.cvae.decode(\n",
    "                torch.randn(target_total, self.cvae.latent_dim).to(self.device),\n",
    "                torch.randint(0, self.num_classes, (target_total,)).to(self.device)\n",
    "            )\n",
    "            initial_labels = initial_labels.argmax(dim=1).cpu().numpy()\n",
    "            \n",
    "            # Smooth labels using GMM\n",
    "            gmm = GaussianMixture(n_components=self.num_classes, random_state=42)\n",
    "            gmm.fit(np.column_stack((self.target_positions_normalized, initial_labels.reshape(-1, 1))))\n",
    "            smoothed_labels = gmm.predict(np.column_stack((self.target_positions_normalized, initial_labels.reshape(-1, 1))))\n",
    "            \n",
    "            # Adjust predictions to match target counts using encoded labels\n",
    "            assigned_labels = self.adjust_predictions(smoothed_labels, target_counts)\n",
    "            \n",
    "            return self.target_positions, assigned_labels\n",
    "\n",
    "    def adjust_predictions(self, predictions, target_counts):\n",
    "        current_counts = pd.Series(predictions).value_counts()\n",
    "        for cell_type_encoded, target_count in target_counts.items():  # Iterate using encoded labels\n",
    "            current_count = current_counts.get(cell_type_encoded, 0)\n",
    "            if current_count < target_count:\n",
    "                # Increase this type\n",
    "                other_types = [t for t in predictions if t != cell_type_encoded]\n",
    "                change_indices = np.random.choice(np.where(np.isin(predictions, other_types))[0], \n",
    "                                                  target_count - current_count, replace=False)\n",
    "                predictions[change_indices] = cell_type_encoded  # Assign encoded label\n",
    "            elif current_count > target_count:\n",
    "                # Decrease this type\n",
    "                change_indices = np.random.choice(np.where(predictions == cell_type_encoded)[0],\n",
    "                                                  current_count - target_count, replace=False)\n",
    "                other_types = [t for t in range(self.num_classes) if t != cell_type_encoded]\n",
    "                predictions[change_indices] = np.random.choice(other_types, size=len(change_indices))\n",
    "        return predictions\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        train_losses = []\n",
    "        dataset = torch.utils.data.TensorDataset(\n",
    "            torch.FloatTensor(self.spatial_coords_normalized),\n",
    "            torch.LongTensor(self.ground_truth_encoded)  # Use encoded labels\n",
    "        )\n",
    "        dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            self.cvae.train()\n",
    "            total_loss = 0\n",
    "\n",
    "            for batch_idx, (data, labels) in enumerate(dataloader):\n",
    "                data, labels = data.to(self.device), labels.to(self.device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                recon_batch, mu, logvar = self.cvae(data, labels)\n",
    "\n",
    "                recon_loss = nn.functional.cross_entropy(recon_batch, labels)\n",
    "                kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "                # Add spatial regularization\n",
    "                spatial_loss = self.spatial_regularization(data, labels, recon_batch)\n",
    "\n",
    "                loss = recon_loss + kl_loss + 0.1 * spatial_loss  # Adjust weight as needed\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            self.scheduler.step()\n",
    "            avg_loss = total_loss / len(dataset)\n",
    "            train_losses.append(avg_loss)\n",
    "\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}] Loss: {avg_loss:.4f}')\n",
    "\n",
    "        return train_losses\n",
    "\n",
    "    def spatial_regularization(self, data, labels, recon_batch):\n",
    "        dist_matrix = torch.cdist(data, data)\n",
    "        sim_matrix = torch.mm(recon_batch, recon_batch.t())\n",
    "        spatial_loss = torch.mean(dist_matrix * sim_matrix)\n",
    "        return spatial_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 主程序\n",
    "if __name__ == \"__main__\":\n",
    "    source_adata = sc.read_h5ad(\"/mnt/volume1/2023SRTP/library/cyr/processed_151673_filtered.h5ad\")\n",
    "    target_adata = sc.read_h5ad(\"/mnt/volume1/2023SRTP/library/cyr/Sample_data_151676.h5ad\")\n",
    "    \n",
    "    print(\"Source data shape:\", source_adata.shape)\n",
    "    print(\"Target data shape:\", target_adata.shape)\n",
    "    \n",
    "    # 初始化和训练模型\n",
    "    model = SpatialAssignment(\n",
    "        adata=source_adata,\n",
    "        target_positions=target_adata.obsm['spatial'],\n",
    "        latent_dim=32,\n",
    "        hidden_size=256,\n",
    "        lr=1e-4,\n",
    "        batch_size=64,\n",
    "        num_epochs=200\n",
    "    )\n",
    "    \n",
    "    train_losses = model.train(num_epochs=400)\n",
    "    \n",
    "    # 分配细胞类型\n",
    "    assigned_positions, assigned_types = model.assign_cell_types()\n",
    "    \n",
    "    # 验证分布\n",
    "    print(\"\\nOriginal distribution:\")\n",
    "    original_dist = pd.Series(source_adata.obs['Ground Truth' if 'Ground Truth' in source_adata.obs.columns else 'layer_guess'].values).value_counts(normalize=True)\n",
    "    print(original_dist)\n",
    "    \n",
    "    print(\"\\nAssigned distribution:\")\n",
    "    assigned_dist = pd.Series(assigned_types).value_counts(normalize=True)\n",
    "    print(assigned_dist)\n",
    "    \n",
    "\n",
    "    # 保存结果\n",
    "    result_adata = target_adata.copy()\n",
    "    result_adata.obs['assigned_cell_type'] = pd.Categorical(model.le.inverse_transform(assigned_types))\n",
    "    result_adata.write_h5ad('assigned_spatial_data.h5ad')\n",
    "\n",
    "    # 绘制训练损失\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses)\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.savefig('training_loss.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 使用示例保持不变，但可以添加验证\n",
    "if __name__ == \"__main__\":\n",
    "    source_adata = sc.read_h5ad(\"/mnt/volume1/2023SRTP/library/cyr/processed_151673_filtered.h5ad\")\n",
    "    target_adata = sc.read_h5ad(\"/mnt/volume1/2023SRTP/library/cyr/Sample_data_151676.h5ad\")\n",
    "    \n",
    "    print(\"Source data shape:\", source_adata.shape)\n",
    "    print(\"Target data shape:\", target_adata.shape)\n",
    "    \n",
    "    # 初始化和训练模型\n",
    "    model = SpatialAssignment(\n",
    "        adata=source_adata,\n",
    "        target_positions=target_adata.obsm['spatial'],\n",
    "        latent_dim=32,\n",
    "        hidden_size=256,\n",
    "        lr=1e-4,\n",
    "        batch_size=64,\n",
    "        num_epochs=200\n",
    "    )\n",
    "    \n",
    "    train_losses = model.train(num_epochs=200)\n",
    "    \n",
    "    # 分配细胞类型\n",
    "    assigned_positions, assigned_types = model.assign_cell_types()\n",
    "    \n",
    "    # 验证分布\n",
    "    print(\"\\nOriginal distribution:\")\n",
    "    original_dist = pd.Series(source_adata.obs['Ground Truth' if 'Ground Truth' in source_adata.obs.columns else 'layer_guess'].values).value_counts(normalize=True)\n",
    "    print(original_dist)\n",
    "    \n",
    "    print(\"\\nAssigned distribution:\")\n",
    "    assigned_dist = pd.Series(assigned_types).value_counts(normalize=True)\n",
    "    print(assigned_dist)\n",
    "    \n",
    "    # 比较分布\n",
    "    compare_distributions(\n",
    "        source_adata.obsm['spatial'],\n",
    "        source_adata.obs['Ground Truth' if 'Ground Truth' in source_adata.obs.columns else 'layer_guess'],\n",
    "        assigned_positions,\n",
    "        assigned_types\n",
    "    )\n",
    "    \n",
    "    # 保存结果\n",
    "    result_adata = target_adata.copy()\n",
    "    result_adata.obs['assigned_cell_type'] = pd.Categorical(assigned_types)\n",
    "    result_adata.write_h5ad('assigned_spatial_data.h5ad')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simulation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
